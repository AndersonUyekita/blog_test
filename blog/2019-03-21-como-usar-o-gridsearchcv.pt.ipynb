{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como usar o `GridSearchCV`\n",
    "\n",
    "#### Tags\n",
    "\n",
    "* Autor: AH Uyekita\n",
    "* Data: 2019/03/22\n",
    "* Post: [Como usar o `GridSearchCV`][post_url]\n",
    "\n",
    "[post_url]: https://andersonuyekita.github.io/notebooks/blog/como-usar-o-gridsearchcv/\n",
    "\n",
    "#### Descrição\n",
    "\n",
    "Esse é um arquivo de acompanhamento do _post_ de mesmo nome.\n",
    "\n",
    "***\n",
    "\n",
    "### Índice\n",
    "- [1. Kernel](#1)\n",
    "- [2. Importação dos _Packages_](#2)\n",
    "- [3. _Datasets_](#3)\n",
    "- [4. _Classifiers_](#4)\n",
    "- [5. Análise dos Resultados](#5)\n",
    "- [6. _Cross Validation_](#6)\n",
    "- [7. _Scoring_](#7)\n",
    "- [8. Técnicas Avançadas](#8)\n",
    "- [9. Conclusões](#9)\n",
    "- [10. Versões dos Packages](#10)\n",
    "\n",
    "***\n",
    "\n",
    "### 1. Kernel <a id='1'></a>\n",
    "\n",
    "Foi usado o Python 3.7, conforme pode ser confirmado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versão do Kernel\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importação dos _Packages_ básicos  <a id='2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos packages básicos.\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Só para evitar a aparição dos warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. _Dataset_ <a id='3'></a>\n",
    "\n",
    "Será usado como exemplo de dataset para a aplicação do `GridSearchCV` o banco de dados de câncer de mama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados de Câncer de mama.\n",
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objeto `cancer` será um dicionário, dessa maneira vamos apenas carregar os dados que nos interessam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do dataset features e vetor labels.\n",
    "features = cancer.data\n",
    "labels = cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. _Classifier_ <a id='4'></a>\n",
    "\n",
    "Esse exemplo terá como base a calibragem dos parâmetros do `AdaBoost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação GridSearchCV.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Importação do AdaBoost.\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o `constructor` do AdaBoost para criar um objeto chamado `clf`, ora doravante _classifier_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do objeto do AdaBoost.\n",
    "clf = AdaBoostClassifier() # Sem nada dentro, pois vamos \"variar\" os parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primeira Iteração\n",
    "\n",
    "Vamos definir quais serão os valores para o `GridSearchCV` testar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros do AdaBoost para o GridSearchCV testar.\n",
    "parametros = {'learning_rate':[0.1, 1,  2],\n",
    "              'n_estimators' :[  1, 5, 10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já temos toda a parte do _classifier_ pronta, falta criar um objeto do `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do objeto do GridSearchCV.\n",
    "grid = GridSearchCV(estimator = clf,          # É o nosso AdaBoost.\n",
    "                    param_grid = parametros,  # É aquele dicionário com valores para serem testados.\n",
    "                    scoring = 'f1',           # Arbitrariamente escolhi o f1, adiante explico com detalhes.\n",
    "                    cv = 20)                  # Idem, arbitratiamente escolhi 20 e adiante será explanado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treina-se o objeto `grid` usando **todo** o _dataset_, pois `cv` foi definido como 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise-deprecating',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.1, 1, 2], 'n_estimators': [1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o grid.\n",
    "grid.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, tem-se o resultado de todas as simulações armazenadas em `grid` cujo resultado pode ser acessa pelo atributo `.cv_results_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>split15_train_score</th>\n",
       "      <th>split16_train_score</th>\n",
       "      <th>split17_train_score</th>\n",
       "      <th>split18_train_score</th>\n",
       "      <th>split19_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1}</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.935532</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>0.938531</td>\n",
       "      <td>0.941512</td>\n",
       "      <td>0.938834</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.938659</td>\n",
       "      <td>0.940067</td>\n",
       "      <td>0.002746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039777</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 5}</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959302</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.951009</td>\n",
       "      <td>0.953757</td>\n",
       "      <td>0.955396</td>\n",
       "      <td>0.953623</td>\n",
       "      <td>0.952518</td>\n",
       "      <td>0.952518</td>\n",
       "      <td>0.954726</td>\n",
       "      <td>0.003314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059464</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10}</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959420</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.957910</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.962319</td>\n",
       "      <td>0.958032</td>\n",
       "      <td>0.958153</td>\n",
       "      <td>0.957910</td>\n",
       "      <td>0.959718</td>\n",
       "      <td>0.001815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008732</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 1}</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.935532</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>0.938531</td>\n",
       "      <td>0.941512</td>\n",
       "      <td>0.938834</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.938659</td>\n",
       "      <td>0.940067</td>\n",
       "      <td>0.002746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023722</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.959641</td>\n",
       "      <td>0.962631</td>\n",
       "      <td>0.967552</td>\n",
       "      <td>0.974815</td>\n",
       "      <td>0.974889</td>\n",
       "      <td>0.976401</td>\n",
       "      <td>0.974889</td>\n",
       "      <td>0.972401</td>\n",
       "      <td>0.006784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.076698</td>\n",
       "      <td>0.021634</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 10}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.986861</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.986861</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.986196</td>\n",
       "      <td>0.003760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005147</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 1}</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.935532</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>0.938531</td>\n",
       "      <td>0.941512</td>\n",
       "      <td>0.938834</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.938659</td>\n",
       "      <td>0.940067</td>\n",
       "      <td>0.002746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.030315</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 5}</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.938346</td>\n",
       "      <td>0.943284</td>\n",
       "      <td>0.941353</td>\n",
       "      <td>0.946746</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.943284</td>\n",
       "      <td>0.946162</td>\n",
       "      <td>0.006454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.046074</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 10}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.043222</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.119782</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>0.116152</td>\n",
       "      <td>0.086629</td>\n",
       "      <td>0.172332</td>\n",
       "      <td>0.254244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.005347      0.001353         0.001450        0.000975   \n",
       "1       0.039777      0.014756         0.003657        0.001633   \n",
       "2       0.059464      0.022415         0.003849        0.002574   \n",
       "3       0.008732      0.004461         0.003047        0.002268   \n",
       "4       0.023722      0.003487         0.002149        0.001061   \n",
       "5       0.076698      0.021634         0.005547        0.003071   \n",
       "6       0.005147      0.003020         0.001149        0.000477   \n",
       "7       0.030315      0.019053         0.002398        0.001743   \n",
       "8       0.046074      0.009788         0.004250        0.003268   \n",
       "\n",
       "  param_learning_rate param_n_estimators  \\\n",
       "0                 0.1                  1   \n",
       "1                 0.1                  5   \n",
       "2                 0.1                 10   \n",
       "3                   1                  1   \n",
       "4                   1                  5   \n",
       "5                   1                 10   \n",
       "6                   2                  1   \n",
       "7                   2                  5   \n",
       "8                   2                 10   \n",
       "\n",
       "                                       params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.1, 'n_estimators': 1}           0.900000   \n",
       "1   {'learning_rate': 0.1, 'n_estimators': 5}           0.923077   \n",
       "2  {'learning_rate': 0.1, 'n_estimators': 10}           0.947368   \n",
       "3     {'learning_rate': 1, 'n_estimators': 1}           0.900000   \n",
       "4     {'learning_rate': 1, 'n_estimators': 5}           1.000000   \n",
       "5    {'learning_rate': 1, 'n_estimators': 10}           1.000000   \n",
       "6     {'learning_rate': 2, 'n_estimators': 1}           0.900000   \n",
       "7     {'learning_rate': 2, 'n_estimators': 5}           0.923077   \n",
       "8    {'learning_rate': 2, 'n_estimators': 10}           0.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         split12_train_score  \\\n",
       "0           0.947368           0.875000       ...                    0.941176   \n",
       "1           0.972973           0.941176       ...                    0.959302   \n",
       "2           0.944444           0.941176       ...                    0.959420   \n",
       "3           0.947368           0.875000       ...                    0.941176   \n",
       "4           0.971429           0.941176       ...                    0.966325   \n",
       "5           0.941176           1.000000       ...                    0.988235   \n",
       "6           0.947368           0.875000       ...                    0.941176   \n",
       "7           0.947368           0.875000       ...                    0.944206   \n",
       "8           0.000000           0.250000       ...                    0.042969   \n",
       "\n",
       "   split13_train_score  split14_train_score  split15_train_score  \\\n",
       "0             0.935532             0.937143             0.938531   \n",
       "1             0.952381             0.951009             0.953757   \n",
       "2             0.960584             0.957910             0.959184   \n",
       "3             0.935532             0.937143             0.938531   \n",
       "4             0.959641             0.962631             0.967552   \n",
       "5             0.977778             0.989721             0.977974   \n",
       "6             0.935532             0.937143             0.938531   \n",
       "7             0.938346             0.943284             0.941353   \n",
       "8             0.125000             0.043222             0.121429   \n",
       "\n",
       "   split16_train_score  split17_train_score  split18_train_score  \\\n",
       "0             0.941512             0.938834             0.940000   \n",
       "1             0.955396             0.953623             0.952518   \n",
       "2             0.962319             0.958032             0.958153   \n",
       "3             0.941512             0.938834             0.940000   \n",
       "4             0.974815             0.974889             0.976401   \n",
       "5             0.986861             0.989781             0.986861   \n",
       "6             0.941512             0.938834             0.940000   \n",
       "7             0.946746             0.943452             0.946903   \n",
       "8             0.119782             0.125448             0.116152   \n",
       "\n",
       "   split19_train_score  mean_train_score  std_train_score  \n",
       "0             0.938659          0.940067         0.002746  \n",
       "1             0.952518          0.954726         0.003314  \n",
       "2             0.957910          0.959718         0.001815  \n",
       "3             0.938659          0.940067         0.002746  \n",
       "4             0.974889          0.972401         0.006784  \n",
       "5             0.989781          0.986196         0.003760  \n",
       "6             0.938659          0.940067         0.002746  \n",
       "7             0.943284          0.946162         0.006454  \n",
       "8             0.086629          0.172332         0.254244  \n",
       "\n",
       "[9 rows x 52 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimindo os resultados.\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que há muitas colunas o que impossibilita a visualização de todos os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'std_fit_time',\n",
       " 'mean_score_time',\n",
       " 'std_score_time',\n",
       " 'param_learning_rate',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'split5_test_score',\n",
       " 'split6_test_score',\n",
       " 'split7_test_score',\n",
       " 'split8_test_score',\n",
       " 'split9_test_score',\n",
       " 'split10_test_score',\n",
       " 'split11_test_score',\n",
       " 'split12_test_score',\n",
       " 'split13_test_score',\n",
       " 'split14_test_score',\n",
       " 'split15_test_score',\n",
       " 'split16_test_score',\n",
       " 'split17_test_score',\n",
       " 'split18_test_score',\n",
       " 'split19_test_score',\n",
       " 'mean_test_score',\n",
       " 'std_test_score',\n",
       " 'rank_test_score',\n",
       " 'split0_train_score',\n",
       " 'split1_train_score',\n",
       " 'split2_train_score',\n",
       " 'split3_train_score',\n",
       " 'split4_train_score',\n",
       " 'split5_train_score',\n",
       " 'split6_train_score',\n",
       " 'split7_train_score',\n",
       " 'split8_train_score',\n",
       " 'split9_train_score',\n",
       " 'split10_train_score',\n",
       " 'split11_train_score',\n",
       " 'split12_train_score',\n",
       " 'split13_train_score',\n",
       " 'split14_train_score',\n",
       " 'split15_train_score',\n",
       " 'split16_train_score',\n",
       " 'split17_train_score',\n",
       " 'split18_train_score',\n",
       " 'split19_train_score',\n",
       " 'mean_train_score',\n",
       " 'std_train_score']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar todas as colunas.\n",
    "pd.DataFrame(grid.cv_results_).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que os \"splits\" no nome das colunas se referem ao número da simulação, isto é, foram feitas 20 simulações para cada conjunto de parâmetros (que vc pode visualizar na coluna `params`). Ao passo que \"train\" e \"test\" referem-se à divisão do _dataset_ em treino e test, note que o `GridSearchCV` já faz isso automaticamente!! Logo, não há necessidade de dividir o _dataset_ usando o `train_test_split` antes de treinar o seu objeto `grid`, pois quando o parâmetros `cv` é configurado para um número inteiro (neste caso 20) é feito \"ocultamente\" um `StratifiedKFolds`, conforme pode ser confirmado na documentação do módulo `GridSearchCV`.\n",
    "\n",
    "$$\\text{Total de Simulacoes} = \\underbrace{9}_{3 \\cdot 3} \\cdot \\underbrace{20}_{n\\_splits} = 180$$\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "cv : int, cross-validation generator or an iterable, optional\n",
    "Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
    "\n",
    "None, to use the default 3-fold cross validation,\n",
    "integer, to specify the number of folds in a (Stratified)KFold,\n",
    "CV splitter,\n",
    "An iterable yielding (train, test) splits as arrays of indices.\n",
    "For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used.\n",
    "\n",
    "Refer User Guide for the various cross-validation strategies that can be used here.\n",
    "\n",
    "Changed in version 0.20: cv default value if None will change from 3-fold to 5-fold in v0.22.\n",
    "```\n",
    "\n",
    "O significado de `score` nos nomes das colunas se referem ao **score** definido na criação do seu objeto `grid`, este exemplo usou o `f1`. Portanto, todas as colunas possuem o valor da métrica `f1` daquela simulação.\n",
    "\n",
    "Vamos adiante para descobrir quais são os parâmetros que produzem os melhores resultados. Para isso, vamos imprimir o melhor `score`, que é o `f1` neste caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963672156448577"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimindo o score.\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos o resultado dos melhores parâmetros, mas não sabemos quais são esses valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'n_estimators': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime os parâmetros que produziram o \".best_score_\".\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso você queira visualizar os resultados dos outros parâmetros, você pode imprimir os resultados e fazer um _subset_. Neste exemplo abaixo selecionei somente `params`, `rank_test_score` e `mean_test_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.915125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 5}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.938154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 10}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.949720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.915125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.963672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.960876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.915125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 5}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.916481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 10}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.174373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       params  rank_test_score  \\\n",
       "0   {'learning_rate': 0.1, 'n_estimators': 1}                6   \n",
       "1   {'learning_rate': 0.1, 'n_estimators': 5}                4   \n",
       "2  {'learning_rate': 0.1, 'n_estimators': 10}                3   \n",
       "3     {'learning_rate': 1, 'n_estimators': 1}                6   \n",
       "4     {'learning_rate': 1, 'n_estimators': 5}                1   \n",
       "5    {'learning_rate': 1, 'n_estimators': 10}                2   \n",
       "6     {'learning_rate': 2, 'n_estimators': 1}                6   \n",
       "7     {'learning_rate': 2, 'n_estimators': 5}                5   \n",
       "8    {'learning_rate': 2, 'n_estimators': 10}                9   \n",
       "\n",
       "   mean_test_score  \n",
       "0         0.915125  \n",
       "1         0.938154  \n",
       "2         0.949720  \n",
       "3         0.915125  \n",
       "4         0.963672  \n",
       "5         0.960876  \n",
       "6         0.915125  \n",
       "7         0.916481  \n",
       "8         0.174373  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime colunas selecionadas.\n",
    "pd.DataFrame(grid.cv_results_)[['params','rank_test_score','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segunda Iteração\n",
    "\n",
    "Observe que o processo de _tuning_ não consiste apenas em uma simulação do `GridSearchCV`, isso deve ser repetido algumas vezes até se chegar na convergência dos parâmetros. O próximo passo seria a simulação com os parâmetros ajustados, tendo diminuído a distância entre os extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novos parametros do AdaBoost para o GridSearchCV testar.\n",
    "parametros = {'learning_rate':[0.5, 1, 1.5],  # Antes era [0.1, 1,  2].\n",
    "              'n_estimators' :[  3, 5,   7]}  # Antes era [  1, 5, 10]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo passo é treinar e visualizar novamente os melhores parâmetros. Infelizmente, teremos que criar novamente o objeto `grid`, uma vez que o atual já está treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'n_estimators': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criação do objeto do GridSearchCV com parametros ajustados.\n",
    "grid = GridSearchCV(estimator = clf,          # É o nosso AdaBoost.\n",
    "                    param_grid = parametros,  # É aquele dicionário com valores para serem testados.\n",
    "                    scoring = 'f1',           # Arbitrariamente escolhi o f1, adiante explico com detalhes.\n",
    "                    cv = 20)                  # Idem, arbitratiamente escolhi 20 e adiante será explanado.\n",
    "\n",
    "# Vamos treinar e imprimir os melhores parâmetros.\n",
    "grid.fit(features,labels).best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que houve uma alteração do `n_estimators`, o que corrobora com a ideia de ajuste do processo de _tuning_. Vamos imprimir o `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9651826300152896"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Novo valor de f1.\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Análise dos Resultados <a id='5'></a>\n",
    "\n",
    "Saliento que o intervalo entre um parâmetro e outro é \"grande\" propositalmente para buscar o melhor parâmetro no maior espectro possível de valores. Note que usar estratégias com inúmeros parâmetros (e muito próximos) não são computacionalmente eficientes, pois você aumentará demasiadamente o tempo de execução do seu modelo.\n",
    "\n",
    "Exemplo de um dicionário de parâmetros computacionalmente pouco eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de parâmetros pouco eficiente.\n",
    "parametros_2 = {'learning_rate':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                'n_estimators' :[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão feitos 2000 simulações, hipoteticamente cada simulação demore em média 1 minuto, totalizará 2000 minutos o que é aproximadamente 33.3 horas.\n",
    "\n",
    "$$\\text{Total de Simulacoes} = \\underbrace{100}_{10 \\cdot 10} \\cdot \\underbrace{20}_{n\\_splits} = 2000$$\n",
    "\n",
    "\n",
    "Até então foram feitos 360 simulações (180 na primeira iteração e mais 180 na segunda).\n",
    "\n",
    "\n",
    "Note que usando esses _toys datasets_ as simulações são rápidas, mas no mundo real elas demoram. Portanto, é bom cultivar as boas práticas. A estratégia mais simples para otimizar os parâmetros é implementar a [_Divide-and-conquer algorithm_][divide_wiki] e isso foi feito inconscientemente ao realizar essas duas iterações.\n",
    "\n",
    "[divide_wiki]: https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, caso seja necessário a criação de um _classifier_ com os melhores parâmetros, você pode usar o `.best_estimator_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
       "          n_estimators=3, random_state=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um objeto que os melhores parametros.\n",
    "clf_otimizado = grid.best_estimator_\n",
    "\n",
    "# Visualizar o objeto para conferir os parametros.\n",
    "clf_otimizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. _Cross Validation_ <a id='6'></a>\n",
    "\n",
    ">O que é Cross Validation?\n",
    "\n",
    "É o uso de um _dataset_ independente para avaliar o grau de generalização do seu modelo.\n",
    "\n",
    "Ressalto que esse **Jupyter Notebook** não tem a finalidade de discorrer sobre esse específico assunto, logo tomo como pressuposto que o leitor saiba exatamente o que é o _cross validation_ e os módulos envolvidos para realizá-lo.\n",
    "\n",
    "Observe que o `cross_validation` é feito ao configurar o parâmetro `cv` do `GridSearchCV`. Quando o cv é um número, entende-se que será feito um `StratifiedKFolds`, ao passo que se for atribuído ao `cv` um objeto do tipo `StratifiedShuffleSplit` ele usará esse objeto para realizar o `cross_validation`.\n",
    "\n",
    "Por último, se o `cv` for omitido na criação do objeto, o `GridSearchCV` entenderá que você fará por conta própria o _cross validation_, isso é o que ele chama de _third party_ _cross validation_.\n",
    "\n",
    "**Exemplo usando o StratifiedKFolds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607829544161065"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo para o uso do StratifiedKFolds com 5 folds.\n",
    "grid_2 = GridSearchCV(estimator = clf,\n",
    "                      param_grid = parametros,\n",
    "                      cv = 5,\n",
    "                      scoring = 'f1')\n",
    "\n",
    "# Imprime o f1\n",
    "grid_2.fit(features,labels).best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplo usando o StratifiedShuffleSplit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9588736081181908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo para o uso do StratifiedShuffleSplit.\n",
    "\n",
    "# Importação do módulo do StratifiedShuffleSplit.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Usando o constructor para criar o objeto sss\n",
    "sss = StratifiedShuffleSplit(n_splits = 20,       # 20 simulações.\n",
    "                             test_size = 0.2,     # 20% do dataset será de testes.\n",
    "                             random_state = 42)   # Permitir a reprodutibilidade.\n",
    "\n",
    "# Criando um objeto do GridSearchCV\n",
    "grid_3 = GridSearchCV(estimator = clf,\n",
    "                      param_grid = parametros,\n",
    "                      cv = sss,\n",
    "                      scoring = 'f1')\n",
    "\n",
    "# Imprime o f1\n",
    "grid_3.fit(features,labels).best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplo omitindo cv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555908682347263"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo omitindo o cv.\n",
    "\n",
    "# Criando um objeto do GridSearchCV sem cv.\n",
    "grid_4 = GridSearchCV(estimator = clf,\n",
    "                      param_grid = parametros,\n",
    "                      scoring = 'f1')\n",
    "\n",
    "# Imprime o f1\n",
    "grid_4.fit(features,labels).best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que neste último caso estou cometendo um erro clássico de _overfitting_, pois estou usando todo o meu dataset para avaliar a performance do meu modelo. Desta maneira, deve-se separar o _features_ e o _labels_ em treino e teste antes de realizar o `fit`. Aconselha-se que use o `cv` interno do `GridSearchCV`, pois ele economizará muitas linhas de código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. _Scoring_ <a id='7'></a>\n",
    "\n",
    "Essa é a métrica utilizada para avaliar cada conjunto de parâmetros simulados pelo `GridSearchCV`, podem ser:\n",
    "\n",
    "* _recall_;\n",
    "* _precision_;\n",
    "* _accuracy_;\n",
    "* f1, ou;\n",
    "* fbeta_score (Obs.: Note que o `f1` é um caso específico do `fbeta_score` quando `beta = 1`.).\n",
    "\n",
    "Caso você tenha eligido o `f1` como os exemplos anteriores, o objeto do `GridSearchCV` terá somente valores de `f1`, isso pode limitar a avaliação do modelo. Desta maneira, introduz o `make_scorer` que é um módulo do Scikit Learn que possibilita o `GridSearchCV` a calcular várias métricas e as armazenando no objeto do `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9567326001272385"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando o Make Scorer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Importando os módulos de cálculo de métricas\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Criando um dicionário com as métricas que desejo calcular.\n",
    "meus_scores = {'accuracy' :make_scorer(accuracy_score),\n",
    "               'recall'   :make_scorer(recall_score),\n",
    "               'precision':make_scorer(precision_score),\n",
    "               'f1'       :make_scorer(fbeta_score, beta = 1)}\n",
    "\n",
    "# Exemplo para o uso scoring igual ao meus_scores.\n",
    "grid_5 = GridSearchCV(estimator = clf,\n",
    "                      param_grid = parametros,\n",
    "                      cv = 5,\n",
    "                      scoring = meus_scores,   # É o meus_scores\n",
    "                      refit = 'f1')            # Observe que foi configurado para f1\n",
    "\n",
    "# Imprime o f1\n",
    "grid_5.fit(features,labels).best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analisar o atributo `.cv_results_` para verificar se houve a adição das colunas com os valores de `recall`, `precision` e `f1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'std_fit_time',\n",
       " 'mean_score_time',\n",
       " 'std_score_time',\n",
       " 'param_learning_rate',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'split0_test_accuracy',\n",
       " 'split1_test_accuracy',\n",
       " 'split2_test_accuracy',\n",
       " 'split3_test_accuracy',\n",
       " 'split4_test_accuracy',\n",
       " 'mean_test_accuracy',\n",
       " 'std_test_accuracy',\n",
       " 'rank_test_accuracy',\n",
       " 'split0_train_accuracy',\n",
       " 'split1_train_accuracy',\n",
       " 'split2_train_accuracy',\n",
       " 'split3_train_accuracy',\n",
       " 'split4_train_accuracy',\n",
       " 'mean_train_accuracy',\n",
       " 'std_train_accuracy',\n",
       " 'split0_test_recall',\n",
       " 'split1_test_recall',\n",
       " 'split2_test_recall',\n",
       " 'split3_test_recall',\n",
       " 'split4_test_recall',\n",
       " 'mean_test_recall',\n",
       " 'std_test_recall',\n",
       " 'rank_test_recall',\n",
       " 'split0_train_recall',\n",
       " 'split1_train_recall',\n",
       " 'split2_train_recall',\n",
       " 'split3_train_recall',\n",
       " 'split4_train_recall',\n",
       " 'mean_train_recall',\n",
       " 'std_train_recall',\n",
       " 'split0_test_precision',\n",
       " 'split1_test_precision',\n",
       " 'split2_test_precision',\n",
       " 'split3_test_precision',\n",
       " 'split4_test_precision',\n",
       " 'mean_test_precision',\n",
       " 'std_test_precision',\n",
       " 'rank_test_precision',\n",
       " 'split0_train_precision',\n",
       " 'split1_train_precision',\n",
       " 'split2_train_precision',\n",
       " 'split3_train_precision',\n",
       " 'split4_train_precision',\n",
       " 'mean_train_precision',\n",
       " 'std_train_precision',\n",
       " 'split0_test_f1',\n",
       " 'split1_test_f1',\n",
       " 'split2_test_f1',\n",
       " 'split3_test_f1',\n",
       " 'split4_test_f1',\n",
       " 'mean_test_f1',\n",
       " 'std_test_f1',\n",
       " 'rank_test_f1',\n",
       " 'split0_train_f1',\n",
       " 'split1_train_f1',\n",
       " 'split2_train_f1',\n",
       " 'split3_train_f1',\n",
       " 'split4_train_f1',\n",
       " 'mean_train_f1',\n",
       " 'std_train_f1']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime todas as colunas.\n",
    "pd.DataFrame(grid_5.cv_results_).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme esperado, agora o objeto `grid` possui todas as métricas desejadas para uma análise detalhada. Abaixo faço um _subset_ para imprimir somente as colunas que são as médias dos _splits_. Note que foi escolhido a impressão dos resultados do _test_ para não incorrermos em _overfitting_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 3}</td>\n",
       "      <td>0.949553</td>\n",
       "      <td>0.928969</td>\n",
       "      <td>0.939066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 5}</td>\n",
       "      <td>0.960771</td>\n",
       "      <td>0.947911</td>\n",
       "      <td>0.954118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 7}</td>\n",
       "      <td>0.960761</td>\n",
       "      <td>0.953387</td>\n",
       "      <td>0.956733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 3}</td>\n",
       "      <td>0.972009</td>\n",
       "      <td>0.920551</td>\n",
       "      <td>0.944569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 5}</td>\n",
       "      <td>0.938394</td>\n",
       "      <td>0.944641</td>\n",
       "      <td>0.941065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 7}</td>\n",
       "      <td>0.952380</td>\n",
       "      <td>0.950321</td>\n",
       "      <td>0.950952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 3}</td>\n",
       "      <td>0.932780</td>\n",
       "      <td>0.905202</td>\n",
       "      <td>0.917460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 5}</td>\n",
       "      <td>0.943998</td>\n",
       "      <td>0.949900</td>\n",
       "      <td>0.946587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 7}</td>\n",
       "      <td>0.977613</td>\n",
       "      <td>0.920708</td>\n",
       "      <td>0.947474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_recall  \\\n",
       "0  {'learning_rate': 0.5, 'n_estimators': 3}          0.949553   \n",
       "1  {'learning_rate': 0.5, 'n_estimators': 5}          0.960771   \n",
       "2  {'learning_rate': 0.5, 'n_estimators': 7}          0.960761   \n",
       "3    {'learning_rate': 1, 'n_estimators': 3}          0.972009   \n",
       "4    {'learning_rate': 1, 'n_estimators': 5}          0.938394   \n",
       "5    {'learning_rate': 1, 'n_estimators': 7}          0.952380   \n",
       "6  {'learning_rate': 1.5, 'n_estimators': 3}          0.932780   \n",
       "7  {'learning_rate': 1.5, 'n_estimators': 5}          0.943998   \n",
       "8  {'learning_rate': 1.5, 'n_estimators': 7}          0.977613   \n",
       "\n",
       "   mean_test_precision  mean_test_f1  \n",
       "0             0.928969      0.939066  \n",
       "1             0.947911      0.954118  \n",
       "2             0.953387      0.956733  \n",
       "3             0.920551      0.944569  \n",
       "4             0.944641      0.941065  \n",
       "5             0.950321      0.950952  \n",
       "6             0.905202      0.917460  \n",
       "7             0.949900      0.946587  \n",
       "8             0.920708      0.947474  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazendo uma subamostragem. \n",
    "pd.DataFrame(grid_5.cv_results_)[['params', 'mean_test_recall', 'mean_test_precision', 'mean_test_f1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que para um computador é muito difícil a tarefa de escolha de um dos conjuntos de parâmetros sem que seja definido qual é a estratégia de escolha. Dessa maneira, define-se o `refit` para que o `GridSearchCV` possa eligir a melhor solução quando solicitado. No caso do exemplo acima foi definido `f1`, logo a solução de melhor `f1` é a `{'learning_rate': 0.5, 'n_estimators': 7}`.\n",
    "\n",
    "Caso seja necessário a impressão de várias métricas de um mesmo conjunto de parâmetros, pode-se usar uma _query_ para selecionar um conjunto de parâmetros. O exemplo abaixo seleciona-se o conjunto com o maior valor de `f1` e imprime os valores de `recall`, `precision` e `f1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 7}</td>\n",
       "      <td>0.960761</td>\n",
       "      <td>0.953387</td>\n",
       "      <td>0.956733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_recall  \\\n",
       "2  {'learning_rate': 0.5, 'n_estimators': 7}          0.960761   \n",
       "\n",
       "   mean_test_precision  mean_test_f1  \n",
       "2             0.953387      0.956733  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando os resultados para imprimir os parâmetros que possuem os melhores.\n",
    "pd.DataFrame(grid_5.cv_results_)[['params',\n",
    "                                  'mean_test_recall',\n",
    "                                  'mean_test_precision',\n",
    "                                  'mean_test_f1']].query('mean_test_f1 == mean_test_f1.max()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a definição de `refit` pode-se usar o `.best_params_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.5, 'n_estimators': 7}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime os melhores parâmetros.\n",
    "grid_5.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ressalto que o atributo `.best_params_` **somente** existirá se o `refit` for definido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Técnicas \"Avançadas\" <a id='8'></a>\n",
    "\n",
    "Somente faça isso se você já entendeu bem como funciona o `GridSearchCV` para um único _classifier_, pois grande parte dos problemas com o `GridSearchCV` é quando se tenta usar ele para vários _classifiers_ de uma maneira sistemática.\n",
    "\n",
    "Ressalto também que essa implementação não usará o `Pipeline`, pois isso será abordado em outro _post_ dedicado ao `Pipeline`.\n",
    "\n",
    "Inicialmente, criarei um dicionário com os _classifiers_ que gostaria de simular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação do classifier Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Importação do classifier Random Forest.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Dicionário com os classifiers que vou simular.\n",
    "classifiers = {'ada': AdaBoostClassifier(),\n",
    "               'dtc': DecisionTreeClassifier(),\n",
    "               'rdf': RandomForestClassifier()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo criado o dicionário com os _classifiers_, aprimoro o dicionário já existente `parametros` para que ele comporte parâmetros de diversos _classifiers_. Isso é feito \"aninhando\" um dicionário dentro do outro, conforme o dicionário `parametros_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros de todos os classifiers para o GridSearchCV testar.\n",
    "parametros_3 = {'ada': {'learning_rate':[0.5, 1, 1.5],\n",
    "                        'n_estimators' :[  3, 5,   7]},\n",
    "                'dtc': {'criterion'    :['gini', 'entropy'], # Alguns parametros para exemplificar\n",
    "                        'max_depth'    :[1, 2, 3]},\n",
    "                'rdf': {'criterion'    :['gini', 'entropy'], # Alguns parametros para exemplificar\n",
    "                        'max_depth'    :[1, 2, 3]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após criar o novo dicionário de parametros e definido o dicionário _classifiers_, pode-se executar as simulações desde que se defina um _classifier_. O exemplo abaixo será para o _AdaBoost_ que é identificado como `ada`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.5, 'n_estimators': 7}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executando o GridSearchCV para o AdaBoost.\n",
    "grid_6 = GridSearchCV(estimator = classifiers['ada'],\n",
    "                      param_grid = parametros_3['ada'],\n",
    "                      cv = 5,\n",
    "                      scoring = 'f1')\n",
    "\n",
    "# Treino e depois imprime os melhores resultados baseado em f1.\n",
    "grid_6.fit(features, labels).best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faremos a mesma simulação para o _Random Forest_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 3}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executando o GridSearchCV para o AdaBoost.\n",
    "grid_7 = GridSearchCV(estimator = classifiers['rdf'],\n",
    "                      param_grid = parametros_3['rdf'],\n",
    "                      cv = 5,\n",
    "                      scoring = 'f1')\n",
    "\n",
    "# Treino e depois imprime os melhores resultados baseado em f1.\n",
    "grid_7.fit(features, labels).best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo, pode-se encapsular essas linhas de código e criar uma função para otimizar o desenvolvimento do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Conclusões <a id='9'></a>\n",
    "\n",
    "Foram abordados quase todos os parâmetros do `GridSearchCV` e muito deles com exemplos. Foi possível observar que o `GridSearchCV` automatiza grande parte do processo de _tuning_, bem como possui um processo de _cross validation_ interno que é muito prático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Versões <a id='10'></a>\n",
    "\n",
    "Usei o [sinfo][sinfo_url] para imprimir as versões de cada módulo e package utilizado neste _Jupyter Notebook_.\n",
    "\n",
    "[sinfo_url]: https://gitlab.com/joelostblom/sinfo\n",
    "\n",
    "```\n",
    "# No terminal/Prompt.\n",
    "pip install sinfo\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "numpy     \t1.15.4\n",
      "pandas    \t0.23.4\n",
      "sklearn   \t0.20.2\n",
      "-----\n",
      "IPython   \t7.2.0\n",
      "jupyter_client\t5.2.4\n",
      "jupyter_core\t4.4.0\n",
      "notebook  \t5.7.4\n",
      "-----\n",
      "Python 3.7.1 (v3.7.1:260ec2c36a, Oct 20 2018, 14:05:16) [MSC v.1915 32 bit (Intel)]\n",
      "Windows-10-10.0.17763-SP0\n",
      "4 logical CPU cores, Intel64 Family 6 Model 61 Stepping 4, GenuineIntel\n",
      "-----\n",
      "Session information updated at 2019-03-23 04:19\n"
     ]
    }
   ],
   "source": [
    "# Importa o sinfo.\n",
    "import sinfo\n",
    "\n",
    "# Imprime as versões dos Packages.\n",
    "sinfo.sinfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
